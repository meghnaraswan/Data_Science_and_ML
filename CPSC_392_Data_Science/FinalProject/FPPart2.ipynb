{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.**\n",
    "\n",
    "(**10 points**; Due Friday November 19th at 11:59pm; PDF) Pretend you're a company who is interested in the dataset you chose. Come up with at **least 7 questions** that you want to answer based on the variables (at the top of this document, **provide a short description of each of the variables in the model**).\n",
    "\n",
    "\n",
    "These questions can be about the relationships between variables, or how well one thing can predict another, clustering...etc, but note that in your final project you must use at least **1 supervised learning model** (includes both regression and classification models), **1 clustering model, and 1 instance of dimensionality reduction** (PCA or LASSO), so keep that in mind when creating questions. You can use more than one of these for a single question (e.g. using PCA and then doing linear regression on the components).\n",
    "\n",
    "You will be graded on the quality of the questions. Questions should be interesting and complex (e.g. questions like \"is this model more than 90% accurate?\" should be expanded to something like \"is this model accurate as measured by accuracy, examination of patterns in the confusion matrix and/or consistent accuracy across gender/race/income/education groups?\"). Questions related to the same model/analysis should be included as 1 question (for example, if you build a model predicting cat weight from cat height, cat age, and cat diet, the question should be somthing like \"which variables have the strongest impact on cat weight?\" instead of having three separate questions \"what is the impact of cat height on cat weight?\", \"what is the impact of cat age on cat weight?\", and \"\"what is the impact of cat diet on cat weight?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [What Makes a Song Likeable?](https://towardsdatascience.com/what-makes-a-song-likeable-dbfdb7abe404)\n",
    "\n",
    "- name: name of the song\n",
    "- duration_ms: The duration of the track in milliseconds\n",
    "- track_number: what number the song is in the playlist\n",
    "- danceability: describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity\n",
    "- energy: represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale\n",
    "- key: the estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.\n",
    "- loudness: the overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n",
    "- mode: indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
    "- speechiness: detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\n",
    "- acousticness: a confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n",
    "- instrumentalness: predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”.\n",
    "- liveness: the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n",
    "- valence: describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)\n",
    "- tempo: the overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n",
    "- type: type of attribute we are looking at (audio features)\n",
    "- id: track id\n",
    "- uri: a unique identifier (link) of a song, album or playlist found in the Share menu\n",
    "- track_href: this attribute specifies the URL of the page the link goes to\n",
    "- analysis_url: playlist information in json format\n",
    "- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our compnay wants to use the Spotify API in order to promote songs to its customers based on what kind of music they like to listen to. To do this, we are using the assumptions of `valence`, `energy`, `tempo`, `mode` provided by Spotify to classify each song as Happy, Angry, Calm or Sad. \n",
    "\n",
    "### Questions:\n",
    "\n",
    "<img src=\"canzoni_distr.jpeg\">\n",
    "\n",
    "1. Journalist Miriam Quick performed an investigation to identify the saddest and the happiest songs ever listed on the top of the Billboard singles chart. To conduct this investigaiton, Quick used numerical parameters of valence and energy, provided by the Spotify Web API. Spotify's internal algorithm measures valence from 0 to 1 based on positive or negative moods, while energy, whcih is also measured from 0 to 1, indicates how lively and dynamic a song is. As we can see in the scatterplot below, Quick splits the graph into 4 quadrants of mood (Happy, Angry, Calm and Sad) based on the valence and energy of each song. Based on this investigation, would **Gaussian Mixture Models (EM)** be able to accurately cluster the data into the 4 quadrants of mood given the `valence` and `energy`? If not, what other assumptions can we make of the clusters (meaning what characterizes each cluster)?\n",
    "\n",
    "2. Tempo is the the overall estimated tempo of a track in beats per minute (BPM). Higher-enrgetic songs tend to be faster in tempo because they are typically played in major key (meaning when mode is 1), whereas slower-paced songs tend to be slower in tempo because they are typically played in minor key (meaning when mode is 0). Would adding `tempo` to the **Gaussian Mixture Models (EM)** clustering model improve the fit of the model? What other assumptions can we make of the clusters? Use a sillhouette score to assess the performance of your model.\n",
    "\n",
    "3. What is the relationship between `valence` and `energy`? Is the relationship between those two variables different for the `mode` of each track? How can you tell? What can we infer about the relationship between `valence` and `energy` of a song given its `mode`? Meaning, what can we say about a track's 4 quadrants of mood (Happy, Angry, Calm and Sad) based on the relationship between `valence` and `energy` of a song given its `mode`?\n",
    "\n",
    "4. Using **KNN**, **Decision Tree**, AND **Logistic Regression Model**, predict the `mode` (major or minor) of each track. Using accuracy and confusion matrices, which model did best and how can you tell? What does this infer about how each model classifies each track?\n",
    "\n",
    "5. Using the classification or regression model with the best performance found in the previous question, is the model more accurate for `tempos` with values less that 110, between 110 and 160, or greater than 160? What are the potential accuracy implications if this model were more accurate for different `tempos`.\n",
    "\n",
    "6. With the **Logistic Regression Model** you made in question #3, record the MSE/R2 for both training/test sets. Discuss the performance of the model. Build a NEW **Logistic Regression Model**, but using **PCA**. Fit your model using the components you found using a scree plot and record the MSE/R2 for both training/test sets. Discuss how the performance of the model built using **PCA** differs from the model built just using **Logistic Regression Model**.\n",
    "\n",
    "7. Looking at the scree plot, how much of the information was retained in the model with using how many components? Looking at the relationship between the priciple components, are there variables that have less of an impact overall on the data? Meaning, could we retain most of the information from the original data with just a few variables? What does this mean in terms of relationships between each of the audio features?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
